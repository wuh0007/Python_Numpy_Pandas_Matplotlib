{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "No.            int64\n",
      "Des.          object\n",
      "water(g)       int64\n",
      "energy         int64\n",
      "protein(g)     int64\n",
      "dtype: object\n",
      "Help on function read_csv in module pandas.io.parsers:\n",
      "\n",
      "read_csv(filepath_or_buffer, sep=',', delimiter=None, header='infer', names=None, index_col=None, usecols=None, squeeze=False, prefix=None, mangle_dupe_cols=True, dtype=None, engine=None, converters=None, true_values=None, false_values=None, skipinitialspace=False, skiprows=None, skipfooter=None, nrows=None, na_values=None, keep_default_na=True, na_filter=True, verbose=False, skip_blank_lines=True, parse_dates=False, infer_datetime_format=False, keep_date_col=False, date_parser=None, dayfirst=False, iterator=False, chunksize=None, compression='infer', thousands=None, decimal=b'.', lineterminator=None, quotechar='\"', quoting=0, escapechar=None, comment=None, encoding=None, dialect=None, tupleize_cols=False, error_bad_lines=True, warn_bad_lines=True, skip_footer=0, doublequote=True, delim_whitespace=False, as_recarray=False, compact_ints=False, use_unsigned=False, low_memory=True, buffer_lines=None, memory_map=False, float_precision=None)\n",
      "    Read CSV (comma-separated) file into DataFrame\n",
      "    \n",
      "    Also supports optionally iterating or breaking of the file\n",
      "    into chunks.\n",
      "    \n",
      "    Additional help can be found in the `online docs for IO Tools\n",
      "    <http://pandas.pydata.org/pandas-docs/stable/io.html>`_.\n",
      "    \n",
      "    Parameters\n",
      "    ----------\n",
      "    filepath_or_buffer : str, pathlib.Path, py._path.local.LocalPath or any object with a read() method (such as a file handle or StringIO)\n",
      "        The string could be a URL. Valid URL schemes include http, ftp, s3, and\n",
      "        file. For file URLs, a host is expected. For instance, a local file could\n",
      "        be file ://localhost/path/to/table.csv\n",
      "    sep : str, default ','\n",
      "        Delimiter to use. If sep is None, will try to automatically determine\n",
      "        this. Separators longer than 1 character and different from '\\s+' will be\n",
      "        interpreted as regular expressions, will force use of the python parsing\n",
      "        engine and will ignore quotes in the data. Regex example: '\\r\\t'\n",
      "    delimiter : str, default ``None``\n",
      "        Alternative argument name for sep.\n",
      "    delim_whitespace : boolean, default False\n",
      "        Specifies whether or not whitespace (e.g. ``' '`` or ``'    '``) will be\n",
      "        used as the sep. Equivalent to setting ``sep='\\+s'``. If this option\n",
      "        is set to True, nothing should be passed in for the ``delimiter``\n",
      "        parameter.\n",
      "    \n",
      "        .. versionadded:: 0.18.1 support for the Python parser.\n",
      "    \n",
      "    header : int or list of ints, default 'infer'\n",
      "        Row number(s) to use as the column names, and the start of the data.\n",
      "        Default behavior is as if set to 0 if no ``names`` passed, otherwise\n",
      "        ``None``. Explicitly pass ``header=0`` to be able to replace existing\n",
      "        names. The header can be a list of integers that specify row locations for\n",
      "        a multi-index on the columns e.g. [0,1,3]. Intervening rows that are not\n",
      "        specified will be skipped (e.g. 2 in this example is skipped). Note that\n",
      "        this parameter ignores commented lines and empty lines if\n",
      "        ``skip_blank_lines=True``, so header=0 denotes the first line of data\n",
      "        rather than the first line of the file.\n",
      "    names : array-like, default None\n",
      "        List of column names to use. If file contains no header row, then you\n",
      "        should explicitly pass header=None\n",
      "    index_col : int or sequence or False, default None\n",
      "        Column to use as the row labels of the DataFrame. If a sequence is given, a\n",
      "        MultiIndex is used. If you have a malformed file with delimiters at the end\n",
      "        of each line, you might consider index_col=False to force pandas to _not_\n",
      "        use the first column as the index (row names)\n",
      "    usecols : array-like, default None\n",
      "        Return a subset of the columns. All elements in this array must either\n",
      "        be positional (i.e. integer indices into the document columns) or strings\n",
      "        that correspond to column names provided either by the user in `names` or\n",
      "        inferred from the document header row(s). For example, a valid `usecols`\n",
      "        parameter would be [0, 1, 2] or ['foo', 'bar', 'baz']. Using this parameter\n",
      "        results in much faster parsing time and lower memory usage.\n",
      "    squeeze : boolean, default False\n",
      "        If the parsed data only contains one column then return a Series\n",
      "    prefix : str, default None\n",
      "        Prefix to add to column numbers when no header, e.g. 'X' for X0, X1, ...\n",
      "    mangle_dupe_cols : boolean, default True\n",
      "        Duplicate columns will be specified as 'X.0'...'X.N', rather than 'X'...'X'\n",
      "    dtype : Type name or dict of column -> type, default None\n",
      "        Data type for data or columns. E.g. {'a': np.float64, 'b': np.int32}\n",
      "        (Unsupported with engine='python'). Use `str` or `object` to preserve and\n",
      "        not interpret dtype.\n",
      "    engine : {'c', 'python'}, optional\n",
      "        Parser engine to use. The C engine is faster while the python engine is\n",
      "        currently more feature-complete.\n",
      "    converters : dict, default None\n",
      "        Dict of functions for converting values in certain columns. Keys can either\n",
      "        be integers or column labels\n",
      "    true_values : list, default None\n",
      "        Values to consider as True\n",
      "    false_values : list, default None\n",
      "        Values to consider as False\n",
      "    skipinitialspace : boolean, default False\n",
      "        Skip spaces after delimiter.\n",
      "    skiprows : list-like or integer, default None\n",
      "        Line numbers to skip (0-indexed) or number of lines to skip (int)\n",
      "        at the start of the file\n",
      "    skipfooter : int, default 0\n",
      "        Number of lines at bottom of file to skip (Unsupported with engine='c')\n",
      "    nrows : int, default None\n",
      "        Number of rows of file to read. Useful for reading pieces of large files\n",
      "    na_values : str or list-like or dict, default None\n",
      "        Additional strings to recognize as NA/NaN. If dict passed, specific\n",
      "        per-column NA values.  By default the following values are interpreted as\n",
      "        NaN: `''`, `'#N/A'`, `'#N/A N/A'`, `'#NA'`, `'-1.#IND'`, `'-1.#QNAN'`, `'-NaN'`, `'-nan'`, `'1.#IND'`, `'1.#QNAN'`, `'N/A'`, `'NA'`, `'NULL'`, `'NaN'`, `'nan'`.\n",
      "    keep_default_na : bool, default True\n",
      "        If na_values are specified and keep_default_na is False the default NaN\n",
      "        values are overridden, otherwise they're appended to.\n",
      "    na_filter : boolean, default True\n",
      "        Detect missing value markers (empty strings and the value of na_values). In\n",
      "        data without any NAs, passing na_filter=False can improve the performance\n",
      "        of reading a large file\n",
      "    verbose : boolean, default False\n",
      "        Indicate number of NA values placed in non-numeric columns\n",
      "    skip_blank_lines : boolean, default True\n",
      "        If True, skip over blank lines rather than interpreting as NaN values\n",
      "    parse_dates : boolean or list of ints or names or list of lists or dict, default False\n",
      "    \n",
      "        * boolean. If True -> try parsing the index.\n",
      "        * list of ints or names. e.g. If [1, 2, 3] -> try parsing columns 1, 2, 3\n",
      "          each as a separate date column.\n",
      "        * list of lists. e.g.  If [[1, 3]] -> combine columns 1 and 3 and parse as\n",
      "            a single date column.\n",
      "        * dict, e.g. {'foo' : [1, 3]} -> parse columns 1, 3 as date and call result\n",
      "          'foo'\n",
      "    \n",
      "        Note: A fast-path exists for iso8601-formatted dates.\n",
      "    infer_datetime_format : boolean, default False\n",
      "        If True and parse_dates is enabled, pandas will attempt to infer the format\n",
      "        of the datetime strings in the columns, and if it can be inferred, switch\n",
      "        to a faster method of parsing them. In some cases this can increase the\n",
      "        parsing speed by ~5-10x.\n",
      "    keep_date_col : boolean, default False\n",
      "        If True and parse_dates specifies combining multiple columns then\n",
      "        keep the original columns.\n",
      "    date_parser : function, default None\n",
      "        Function to use for converting a sequence of string columns to an array of\n",
      "        datetime instances. The default uses ``dateutil.parser.parser`` to do the\n",
      "        conversion. Pandas will try to call date_parser in three different ways,\n",
      "        advancing to the next if an exception occurs: 1) Pass one or more arrays\n",
      "        (as defined by parse_dates) as arguments; 2) concatenate (row-wise) the\n",
      "        string values from the columns defined by parse_dates into a single array\n",
      "        and pass that; and 3) call date_parser once for each row using one or more\n",
      "        strings (corresponding to the columns defined by parse_dates) as arguments.\n",
      "    dayfirst : boolean, default False\n",
      "        DD/MM format dates, international and European format\n",
      "    iterator : boolean, default False\n",
      "        Return TextFileReader object for iteration or getting chunks with\n",
      "        ``get_chunk()``.\n",
      "    chunksize : int, default None\n",
      "        Return TextFileReader object for iteration. `See IO Tools docs for more\n",
      "        information\n",
      "        <http://pandas.pydata.org/pandas-docs/stable/io.html#io-chunking>`_ on\n",
      "        ``iterator`` and ``chunksize``.\n",
      "    compression : {'infer', 'gzip', 'bz2', 'zip', 'xz', None}, default 'infer'\n",
      "        For on-the-fly decompression of on-disk data. If 'infer', then use gzip,\n",
      "        bz2, zip or xz if filepath_or_buffer is a string ending in '.gz', '.bz2',\n",
      "        '.zip', or 'xz', respectively, and no decompression otherwise. If using\n",
      "        'zip', the ZIP file must contain only one data file to be read in.\n",
      "        Set to None for no decompression.\n",
      "    \n",
      "        .. versionadded:: 0.18.1 support for 'zip' and 'xz' compression.\n",
      "    \n",
      "    thousands : str, default None\n",
      "        Thousands separator\n",
      "    decimal : str, default '.'\n",
      "        Character to recognize as decimal point (e.g. use ',' for European data).\n",
      "    lineterminator : str (length 1), default None\n",
      "        Character to break file into lines. Only valid with C parser.\n",
      "    quotechar : str (length 1), optional\n",
      "        The character used to denote the start and end of a quoted item. Quoted\n",
      "        items can include the delimiter and it will be ignored.\n",
      "    quoting : int or csv.QUOTE_* instance, default None\n",
      "        Control field quoting behavior per ``csv.QUOTE_*`` constants. Use one of\n",
      "        QUOTE_MINIMAL (0), QUOTE_ALL (1), QUOTE_NONNUMERIC (2) or QUOTE_NONE (3).\n",
      "        Default (None) results in QUOTE_MINIMAL behavior.\n",
      "    escapechar : str (length 1), default None\n",
      "        One-character string used to escape delimiter when quoting is QUOTE_NONE.\n",
      "    comment : str, default None\n",
      "        Indicates remainder of line should not be parsed. If found at the beginning\n",
      "        of a line, the line will be ignored altogether. This parameter must be a\n",
      "        single character. Like empty lines (as long as ``skip_blank_lines=True``),\n",
      "        fully commented lines are ignored by the parameter `header` but not by\n",
      "        `skiprows`. For example, if comment='#', parsing '#empty\\na,b,c\\n1,2,3'\n",
      "        with `header=0` will result in 'a,b,c' being\n",
      "        treated as the header.\n",
      "    encoding : str, default None\n",
      "        Encoding to use for UTF when reading/writing (ex. 'utf-8'). `List of Python\n",
      "        standard encodings\n",
      "        <https://docs.python.org/3/library/codecs.html#standard-encodings>`_\n",
      "    dialect : str or csv.Dialect instance, default None\n",
      "        If None defaults to Excel dialect. Ignored if sep longer than 1 char\n",
      "        See csv.Dialect documentation for more details\n",
      "    tupleize_cols : boolean, default False\n",
      "        Leave a list of tuples on columns as is (default is to convert to\n",
      "        a Multi Index on the columns)\n",
      "    error_bad_lines : boolean, default True\n",
      "        Lines with too many fields (e.g. a csv line with too many commas) will by\n",
      "        default cause an exception to be raised, and no DataFrame will be returned.\n",
      "        If False, then these \"bad lines\" will dropped from the DataFrame that is\n",
      "        returned. (Only valid with C parser)\n",
      "    warn_bad_lines : boolean, default True\n",
      "        If error_bad_lines is False, and warn_bad_lines is True, a warning for each\n",
      "        \"bad line\" will be output. (Only valid with C parser).\n",
      "    \n",
      "    Returns\n",
      "    -------\n",
      "    result : DataFrame or TextParser\n",
      "\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "food_info = pd.read_csv(\"food.csv\")\n",
    "print(type(food_info))\n",
    "print(food_info.dtypes)\n",
    "print(help(pd.read_csv))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10, 5)\n"
     ]
    }
   ],
   "source": [
    "# food_info.head()\n",
    "# food_info.tail()\n",
    "# print(food_info.columns)\n",
    "# print(food_info.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No.               1\n",
      "Des.       Butter 1\n",
      "water            12\n",
      "energy          112\n",
      "protein          21\n",
      "Name: 0, dtype: object\n"
     ]
    }
   ],
   "source": [
    "print(food_info.loc[0]) #first row info\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# object - string values\n",
    "# int - integer values\n",
    "# float - float values\n",
    "# datetime - time values\n",
    "# bool - boolean values\n",
    "# print(food_info.dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>No.</th>\n",
       "      <th>Des.</th>\n",
       "      <th>water</th>\n",
       "      <th>energy</th>\n",
       "      <th>protein</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3.0</td>\n",
       "      <td>Butter 3</td>\n",
       "      <td>33.0</td>\n",
       "      <td>124.0</td>\n",
       "      <td>34.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6.0</td>\n",
       "      <td>Cheese 3</td>\n",
       "      <td>87.0</td>\n",
       "      <td>677.0</td>\n",
       "      <td>345.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    No.      Des.  water  energy  protein\n",
       "2   3.0  Butter 3   33.0   124.0     34.0\n",
       "5   6.0  Cheese 3   87.0   677.0    345.0\n",
       "10  NaN       NaN    NaN     NaN      NaN"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# return a dataframe containning the rows at indexes 3,4,5,and 6\n",
    "food_info.loc[3:6]\n",
    "\n",
    "# return a dataframe containning the rows at indexes 2,5,and 10.\n",
    "food_info.loc[[2,5,10]]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0     1\n",
       "1     2\n",
       "2     3\n",
       "3     4\n",
       "4     5\n",
       "5     6\n",
       "6     7\n",
       "7     8\n",
       "8     9\n",
       "9    10\n",
       "Name: No., dtype: int64"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# series object representing the \"No.\" column\n",
    "No_col = food_info['No.']\n",
    "print(No_col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>No.</th>\n",
       "      <th>Des.</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Butter 1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Butter 2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Butter 3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>Cheese 1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Cheese 2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>Cheese 3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "      <td>Cheese 4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8</td>\n",
       "      <td>Cheese 5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9</td>\n",
       "      <td>Cheese 6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10</td>\n",
       "      <td>cheese 7</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   No.      Des.\n",
       "0    1  Butter 1\n",
       "1    2  Butter 2\n",
       "2    3  Butter 3\n",
       "3    4  Cheese 1\n",
       "4    5  Cheese 2\n",
       "5    6  Cheese 3\n",
       "6    7  Cheese 4\n",
       "7    8  Cheese 5\n",
       "8    9  Cheese 6\n",
       "9   10  cheese 7"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# two columns\n",
    "food_info[['No.','Des.']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['No.', 'Des.', 'water(g)', 'energy', 'protein(g)']\n",
      "   water(g)  protein(g)\n",
      "0        12          21\n",
      "1        32          12\n",
      "2        33          34\n",
      "3        44         543\n",
      "4        21         675\n",
      "5        87         345\n",
      "6        54          68\n",
      "7         9           9\n",
      "8        87         567\n",
      "9        89        6578\n",
      "water(g)      12\n",
      "protein(g)    21\n",
      "Name: 0, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "col_names = food_info.columns.tolist()\n",
    "print(col_names)\n",
    "gram_columns = []\n",
    "\n",
    "for i in col_names:\n",
    "    if i.endswith('(g)'):\n",
    "        gram_columns.append(i)\n",
    "gram_df = food_info[gram_columns]\n",
    "print(gram_df)\n",
    "print(gram_df.loc[0])"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda env:Anaconda3]",
   "language": "python",
   "name": "conda-env-Anaconda3-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
